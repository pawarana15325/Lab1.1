{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bcf66fb-3067-462b-8edb-cf35d4a11c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.1.2\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.9.0 mpmath-1.3.0 networkx-3.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: torch==2.4.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torchvision) (2.4.1)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from torch==2.4.1->torchvision) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, torchvision\n",
      "Successfully installed pillow-10.4.0 torchvision-0.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7677beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "print (torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7bafe",
   "metadata": {},
   "source": [
    "## 1. Interconversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c2d95",
   "metadata": {},
   "source": [
    "### 1.1 Converting from NumPy to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a0d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2tensor(x):\n",
    "    \"\"\"\n",
    "    Creates a torch.Tensor from a numpy.ndarray.\n",
    "\n",
    "    Parameters:\n",
    "    x (numpy.ndarray): 1-dimensional numpy array.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    x = torch.tensor(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5097e1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "print(type(numpy2tensor(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4275906",
   "metadata": {},
   "source": [
    "### 1.2 Converting from PyTorch Tensor to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2numpy(x):\n",
    "    \"\"\"\n",
    "    Creates a numpy.ndarray from a torch.Tensor.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: 1-dimensional numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    x = x.numpy()\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a935d0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "print(type(tensor2numpy(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f886b1",
   "metadata": {},
   "source": [
    "## 2. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ffc66",
   "metadata": {},
   "source": [
    "### 2.1 Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55174223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_dot(x, y):\n",
    "    \"\"\"\n",
    "    Dot product of two tensors.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.int64: scalar quantity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    z = torch.dot(x, y)\n",
    "    \n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be34273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7082791)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_dot(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac0ab2",
   "metadata": {},
   "source": [
    "### 2.2 Outer Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae487c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_outer(x, y):\n",
    "    \"\"\"\n",
    "    Compute the outer product of two vectors.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: 2-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    z = torch.outer(x, y)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "357c4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  59092, -144096,  136512,  ...,  -53088,  -86268,   53404],\n",
      "        [  82467, -201096,  190512,  ...,  -74088, -120393,   74529],\n",
      "        [-122111,  297768, -282096,  ...,  109704,  178269, -110357],\n",
      "        ...,\n",
      "        [-144551,  352488, -333936,  ...,  129864,  211029, -130637],\n",
      "        [-179707,  438216, -415152,  ...,  161448,  262353, -162409],\n",
      "        [  88825, -216600,  205200,  ...,  -79800, -129675,   80275]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_outer(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40d24a",
   "metadata": {},
   "source": [
    "### 2.3 Hadamard Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed294b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_multiply(x, y):\n",
    "    \"\"\"\n",
    "    Multiply arguments element-wise.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    z = torch.mul(x, y)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b19ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  59092, -201096, -282096,  ...,  129864,  262353,   80275])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_multiply(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8272fc",
   "metadata": {},
   "source": [
    "### 2.4 Sum-Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2fab1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_sumproduct(x, y):\n",
    "    \"\"\"\n",
    "    Sum over all the dimensions of the outer product of two vectors.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.int64: scalar quantity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "    z = z.to(torch.int64)\n",
    "    \n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a81e330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(265421520)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_sumproduct(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77736de2",
   "metadata": {},
   "source": [
    "### **3. Tensor Manipulation**\n",
    "\n",
    "PyTorch offers a wide range of tensor manipulation tasks that empower users to efficiently process and transform data within neural network workflows.\n",
    "These tasks include :\n",
    "1.  Flatten\n",
    "2.  Unsqueeze\n",
    "3.  Squeeze\n",
    "4.  Reshape\n",
    "5.  Transpose\n",
    "6.  Permute\n",
    "7.  Concatenation\n",
    "8.  Stack\n",
    "9.  Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f0882a",
   "metadata": {},
   "source": [
    "#### 3.1 Flatten\n",
    "\n",
    "In this task, you will implement the flatten function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_flatten`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49996c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_flatten(input_tensor):\n",
    "    \"\"\"\n",
    "    Reshapes a tensor into a 1-dimensional array \n",
    "    while maintaining the order of elements.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    z = torch.flatten(input_tensor)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "351f4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[[  2,   5, -10,  -7],\n",
      "         [ -7,  -3,  -1,   9],\n",
      "         [  8,  -6,  -4,   2]],\n",
      "\n",
      "        [[ -9,  -4,  -3,   4],\n",
      "         [  7,  -5,   3,  -2],\n",
      "         [ -1,   9,   6,   9]]])\n",
      "New tensor([  2,   5, -10,  -7,  -7,  -3,  -1,   9,   8,  -6,  -4,   2,  -9,  -4,\n",
      "         -3,   4,   7,  -5,   3,  -2,  -1,   9,   6,   9])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-10, 10, size=(2,3,4))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_flatten(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03692c",
   "metadata": {},
   "source": [
    "#### 3.2 Unsqueeze\n",
    "\n",
    "In this task, you will implement the unsqueeze function for torch tensors along given dimension.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_unsqueeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4d2af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_unsqueeze(X,dim):\n",
    "    \"\"\"\n",
    "    Adds a new dimension to a tensor at the specified position 'dim'.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 2-dimensional torch tensor.\n",
    "\n",
    "    dim (int): scalar.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: 3-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.unsqueeze(X, dim)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7f568ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[4, 0, 3],\n",
      "        [3, 3, 1]])\n",
      "New tensor([[[4, 0, 3],\n",
      "         [3, 3, 1]]])\n",
      "Shape before unsqueeze:  torch.Size([2, 3])\n",
      "Shape after unsqueeze:  torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 5, size=(2,3))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_unsqueeze(X,0))\n",
    "print(\"Shape before unsqueeze: \",X.shape)\n",
    "print(\"Shape after unsqueeze: \",PYTORCH_unsqueeze(X,0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d380dd",
   "metadata": {},
   "source": [
    "#### 3.3 Squeeze\n",
    "\n",
    "In this task, you will implement the squeeze function for torch tensors along axis with dimension 1 (axis = 0).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_squeeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fc9effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_squeeze(X,dim):\n",
    "    \"\"\"\n",
    "    Removes dimension to a tensor at the specified position 'dim'.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 2-dimensional torch tensor.\n",
    "\n",
    "    dim (integer): scalar.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.squeeze(X, dim)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f176aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[5, 0, 3, 3, 7]])\n",
      "New tensor([5, 0, 3, 3, 7])\n",
      "Shape of tensor before squeeze:  torch.Size([1, 5])\n",
      "Shape of tensor after squeeze:  torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(1,5))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_squeeze(X,0))\n",
    "print(\"Shape of tensor before squeeze: \",X.shape)\n",
    "print(\"Shape of tensor after squeeze: \",PYTORCH_squeeze(X,0).shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c1ceb",
   "metadata": {},
   "source": [
    "#### 3.4 Reshape\n",
    "\n",
    "In this task, you will implement the reshape function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac1eeedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_reshape(X,new_shape):\n",
    "    \"\"\"\n",
    "    Reorganizes the tensor's elements to match a specified shape \n",
    "    while maintaining the same number of elements.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    new_shape (tuple): tuple with 3 elements \n",
    "    which represents the new shape of the tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: torch tensor of dimension 'new_shape'.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.reshape(X,new_shape)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "795243bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[5, 0, 3, 3, 7, 9, 3, 5, 2, 4],\n",
      "        [7, 6, 8, 8, 1, 6, 7, 7, 8, 1],\n",
      "        [5, 9, 8, 9, 4, 3, 0, 3, 5, 0]])\n",
      "New tensor([[[5, 0, 3, 3, 7],\n",
      "         [9, 3, 5, 2, 4],\n",
      "         [7, 6, 8, 8, 1]],\n",
      "\n",
      "        [[6, 7, 7, 8, 1],\n",
      "         [5, 9, 8, 9, 4],\n",
      "         [3, 0, 3, 5, 0]]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(3,10))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_reshape(X,(2,3,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4d891",
   "metadata": {},
   "source": [
    "#### 3.5 Transpose\n",
    "\n",
    "In this task, you will implement the transpose function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_transpose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d7563da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_transpose(X,dim0,dim1):\n",
    "    \"\"\"\n",
    "    Reorganizes the tensor's elements and shape effectively \n",
    "    by swapping along given direction.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    dim0 (int): the first dimension to be transposed.\n",
    "\n",
    "    dim1 (int): the second dimension to be transposed.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: torch tensor of transposed version input.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.transpose(X,dim0,dim1)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4592cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[[5, 0, 3, 3],\n",
      "         [7, 9, 3, 5],\n",
      "         [2, 4, 7, 6]]])\n",
      "New tensor([[[5, 7, 2],\n",
      "         [0, 9, 4],\n",
      "         [3, 3, 7],\n",
      "         [3, 5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(1,3,4))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_transpose(X,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba30c58",
   "metadata": {},
   "source": [
    "#### 3.6 Permute\n",
    "\n",
    "In this task, you will implement the permute function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_permute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c258e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_permute(X,dims):\n",
    "    \"\"\"\n",
    "    Reorganizes the the dimensions of a tensor according \n",
    "    to a specified permutation tuple while maintaining the data's order.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    dims (tuple): tuple of integers that represents axis to be permuted\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: torch tensor of permuted version input.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.permute(X,dims)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a93e7b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[[5, 0, 3, 3],\n",
      "         [7, 9, 3, 5],\n",
      "         [2, 4, 7, 6]],\n",
      "\n",
      "        [[8, 8, 1, 6],\n",
      "         [7, 7, 8, 1],\n",
      "         [5, 9, 8, 9]]])\n",
      "New tensor([[[5, 7, 2],\n",
      "         [8, 7, 5]],\n",
      "\n",
      "        [[0, 9, 4],\n",
      "         [8, 7, 9]],\n",
      "\n",
      "        [[3, 3, 7],\n",
      "         [1, 8, 8]],\n",
      "\n",
      "        [[3, 5, 6],\n",
      "         [6, 1, 9]]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3,4))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_permute(X,(2,0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c861b",
   "metadata": {},
   "source": [
    "#### 3.7 Concatenate\n",
    "\n",
    "In this task, you will implement the Concatenate function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_concatenate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50e39610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_concatenate(tensors,dim):\n",
    "    \"\"\"\n",
    "    Reorganizes the the dimensions of a tensor according to \n",
    "    a specified permutation tuple while maintaining the data's order.\n",
    "\n",
    "    Parameters:\n",
    "    tensors (tuple): tuple of Tensors with same shape except \n",
    "    in concatenate dimension.\n",
    "\n",
    "    dim (int): concatenate dimension\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: concatenated tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.cat(tensors,dim)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a3ae4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x tensor([[[5, 0, 3, 3],\n",
      "         [7, 9, 3, 5],\n",
      "         [2, 4, 7, 6]],\n",
      "\n",
      "        [[8, 8, 1, 6],\n",
      "         [7, 7, 8, 1],\n",
      "         [5, 9, 8, 9]]])\n",
      "Original y tensor([[[0, 0, 1],\n",
      "         [2, 0, 2],\n",
      "         [0, 1, 1]],\n",
      "\n",
      "        [[2, 0, 1],\n",
      "         [1, 1, 0],\n",
      "         [2, 0, 2]]])\n",
      "New tensor([[[5, 0, 3, 3, 0, 0, 1],\n",
      "         [7, 9, 3, 5, 2, 0, 2],\n",
      "         [2, 4, 7, 6, 0, 1, 1]],\n",
      "\n",
      "        [[8, 8, 1, 6, 2, 0, 1],\n",
      "         [7, 7, 8, 1, 1, 1, 0],\n",
      "         [5, 9, 8, 9, 2, 0, 2]]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3,4))\n",
    "Y = np.random.randint(0, 3, size=(2,3,3))\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "print('Original x',X)\n",
    "print('Original y',Y)\n",
    "print('New',PYTORCH_concatenate((X,Y),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a548e69",
   "metadata": {},
   "source": [
    "#### 3.8 Stack\n",
    "\n",
    "In this task, you will implement the stack function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_stack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5a23cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_stack(tensors,dim):\n",
    "    \"\"\"\n",
    "    In contrast to Concatenation, which merges two tensors \n",
    "    along an existing dimension,\n",
    "    Stack creates a new dimension to combine tensors.\n",
    "\n",
    "    Parameters:\n",
    "    tensors (tuple):  tuple of tensors to be stacked\n",
    "    dim (int): dimension to insert.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: stacked tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.stack(tensors,dim)\n",
    "    \n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec1ad279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x tensor([[5, 0, 3],\n",
      "        [3, 7, 9]])\n",
      "Original y tensor([[1, 2, 0],\n",
      "        [2, 0, 0]])\n",
      "New tensor([[[5, 0, 3],\n",
      "         [1, 2, 0]],\n",
      "\n",
      "        [[3, 7, 9],\n",
      "         [2, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3))\n",
    "Y = np.random.randint(0, 3, size=(2,3))\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "print('Original x',X)\n",
    "print('Original y',Y)\n",
    "print('New',PYTORCH_stack((X,Y),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fecd2a",
   "metadata": {},
   "source": [
    "#### 3.9 Padding\n",
    "\n",
    "In this task, you will implement the padding  function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_padding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "939bdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_padding(X,pad_widths):\n",
    "    \"\"\"\n",
    "    This involves adding extra elements (usually zeros) \n",
    "    around the edges of a tensor.\n",
    "    We will encounter this during convolutional operations \n",
    "    to control the spatial dimensions of the output.\n",
    "\n",
    "    Parameters:\n",
    "    X (torch.Tensor): input tensor which is to be padded.\n",
    "    pad_widths (tuple): even number of elements in tuple \n",
    "    that represents padding widths in the order \n",
    "    columns,rows and channels.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: stacked tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO\n",
    "    z = torch.padding(X,pad_widths)\n",
    "\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8045aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor([[[6, 1],\n",
      "         [4, 4]],\n",
      "\n",
      "        [[8, 4],\n",
      "         [6, 3]]])\n",
      "New tensor([[[0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 6, 1, 0, 0],\n",
      "         [0, 0, 4, 4, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 8, 4, 0, 0],\n",
      "         [0, 0, 6, 3, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(1, 10, size=(2,2,2))\n",
    "X = numpy2tensor(X)\n",
    "print('Original',X)\n",
    "print('New',PYTORCH_padding(X,(2,2,1,1,0,0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
